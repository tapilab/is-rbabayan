{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy \n",
    "import pickle\n",
    "import os\n",
    "from geopy.geocoders import Nominatim\n",
    "import countries\n",
    "import datetime \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TWEET_PATH = 'Tweets/'\n",
    "ACCESS_TOKEN = '3007366663-QU3WM6hrAXEAfelPzdCpv713LOB8D7LgtsuvZWL'\n",
    "ACCESS_SECRET = 'RzDTCkg3xoZfEmc3bGNXypponiq06ak9rZxiziXzx7nkO'\n",
    "CONSUMER_KEY = 'nlbCSYMdqtyKpANbLQOl6ITKZ'\n",
    "CONSUMER_SECRET = 'wY1CXDFLcN03H94BQo96KzKW47J2nfvoQBr4x5XL96POTV9Bbj'\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "api.wait_on_rate_limit = True\n",
    "api.wait_on_rate_limit_notify = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_tweets(user_id, api):\n",
    "\n",
    "\n",
    "    alltweets = []\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(user_id = user_id,count=200)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print \"getting tweets before %s\" % (oldest)\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(user_id = user_id, count=200, max_id=oldest)\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print \"...%s tweets downloaded so far\" % (len(alltweets))\n",
    "    \n",
    "    return alltweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_tweets = get_all_tweets(40428817,api)\n",
    "\n",
    "#for tweet in all_tweets:\n",
    "    #print tweet.coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f = open('all_tweets.txt', 'w')\n",
    "#pickle.dump(all_tweets, f)\n",
    "#f.close()\n",
    "\n",
    "#f = open('all_tweets.txt', 'r')\n",
    "#all_tweets2 = pickle.load(f)\n",
    "#f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_followers(filename, screen_name, api):\n",
    "    \n",
    "    uscis_followers = []\n",
    "    for page in tweepy.Cursor(api.followers_ids, screen_name = screen_name).pages():\n",
    "        uscis_followers.extend(page)\n",
    "        time.sleep(60)\n",
    "    \n",
    "    #write into a file\n",
    "    f = open(filename , 'w')\n",
    "    for id in uscis_followers:\n",
    "        f.write(str(id) + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "    return uscis_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#uscis_followers = get_followers('uscis_followers','USCIS' ,api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65996\n"
     ]
    }
   ],
   "source": [
    "f = open('uscis_followers', 'r')\n",
    "uscis_followers = []\n",
    "for line in f:\n",
    "    uscis_followers.append(f.read)\n",
    "f.close()\n",
    "print len(uscis_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prune_followers(uscis_followers, min_status_count, api):\n",
    "    \n",
    "    pruned = []\n",
    "    \n",
    "    for id in uscis_followers:\n",
    "        try:\n",
    "            user = api.get_user(id)\n",
    "        \n",
    "            if not user.protected:\n",
    "                if user.geo_enabled:\n",
    "                    if user.statuses_count > min_status_count:\n",
    "                        pruned.append(id)\n",
    "                        print id\n",
    "        except:\n",
    "            print 'error caught!'\n",
    "            pass\n",
    "    \n",
    "    return pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pruned_followers1 = prune_followers(uscis_followers[0:6000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers2 = prune_followers(uscis_followers[6000:12000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers3 = prune_followers(uscis_followers[12000:18000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers4 = prune_followers(uscis_followers[18000:24000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers5 = prune_followers(uscis_followers[24000:30000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers6 = prune_followers(uscis_followers[30000:36000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers7 = prune_followers(uscis_followers[36000:42000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers8 = prune_followers(uscis_followers[42000:48000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers9 = prune_followers(uscis_followers[48000:54000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers10 = prune_followers(uscis_followers[54000:60000], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pruned_followers11 = prune_followers(uscis_followers[60000:], 100, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_and_save_tweets_one_user(user_id, api):\n",
    "    all_tweets = get_all_tweets(user_id, api)\n",
    "    f = open (TWEET_PATH + str(user_id) , 'w')\n",
    "    pickle.dump(all_tweets, f)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_and_save_tweets_all_users(followers_pruned_id, api):\n",
    "    for id in followers_pruned_id:\n",
    "        get_and_save_tweets_one_user(id, api)\n",
    "        print 'tweets of ' , id , 'were saved!' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_and_save_tweets_all_users(pruned_followers, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_ids_Twetter_folder():\n",
    "    all_followers = []\n",
    "    for dirs, root, files in os.walk(TWEET_PATH):\n",
    "        for file in files:\n",
    "            if not file.startswith('.'):\n",
    "                all_followers.append(file) \n",
    "    return all_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_followers = get_user_ids_Twetter_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class User_Tweet(object):\n",
    "\n",
    "    def __init__(self,date,text,country):\n",
    "        self.date = date\n",
    "        self.text = text\n",
    "        self.country = country\n",
    "    \n",
    "    def __cmp__(self,other):\n",
    "        if self.date < other.date:\n",
    "            return -1\n",
    "        elif self.date == other.date:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_user_timelines_dic(followers_ids):\n",
    "    \n",
    "    users_timelines = {}\n",
    "    \n",
    "    for user_id in followers_ids:\n",
    "        \n",
    "        timeline = []\n",
    "        \n",
    "        file_name = TWEET_PATH + str(user_id)\n",
    "        f = open(file_name,'r')\n",
    "        tweets = pickle.load(f)\n",
    "        f.close()\n",
    "    \n",
    "        for tweet in tweets:\n",
    "            if tweet.place is not None:\n",
    "                user_tweet = User_Tweet(tweet.created_at,tweet.text,tweet.place.country)\n",
    "                timeline.append(user_tweet)\n",
    "                \n",
    "        users_timelines[user_id] = timeline\n",
    "        \n",
    "    return users_timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_timelines = create_user_timelines_dic(all_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_immigrants(users_timelines):\n",
    "    \n",
    "    immigrants = {}\n",
    "    \n",
    "    for user_id in users_timelines:\n",
    "        timeline = users_timelines[user_id]\n",
    "        sorted_timeline = sorted(timeline)\n",
    "    \n",
    "        countries = []\n",
    "        for user_tweet in sorted_timeline:\n",
    "            if user_tweet.country not in countries:\n",
    "                countries.append(user_tweet.country)\n",
    "            \n",
    "        if (len(countries) > 1):\n",
    "            if sorted_timeline[-1].country == countries[-1]:\n",
    "\n",
    "                #find the time of last tweet in the previous country\n",
    "                i = len(sorted_timeline) - 1\n",
    "                last_tweet_previous_country = sorted_timeline[i]\n",
    "                while(last_tweet_previous_country.country != countries[-2]):\n",
    "                    i = i - 1\n",
    "                    last_tweet_previous_country = sorted_timeline[i]\n",
    "                \n",
    "                duration = sorted_timeline[-1].date - last_tweet_previous_country.date\n",
    "            \n",
    "                if duration.days > 90:\n",
    "                    immigrants[user_id] = duration.days\n",
    "    return immigrants             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "immigrants = find_immigrants(users_timelines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
